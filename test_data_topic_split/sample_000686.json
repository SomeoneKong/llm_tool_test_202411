{"sample_idx": 27, "start_block_idx": 2487, "last_block_idx": 2598, "block_list": [{"block_idx": 0, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Yeah."}, {"block_idx": 1, "token_num": 50, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "So we're now sort of like going into politics and I the the case I would make to the politician is at the point where the most legibly credible expert who recently won the Nobel Prize about it says like, well, personally I'm over 50%."}, {"block_idx": 2, "token_num": 16, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Like my sort of first order personal assessment is over 50% existential catastrophe."}, {"block_idx": 3, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "That's that's code for killing everyone."}, {"block_idx": 4, "token_num": 29, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "But, you know, like, taking into account what other people are saying, I would say in public more like 10 to 20%."}, {"block_idx": 5, "token_num": 27, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And the people who've been studying the issue longest are like, yeah, this kind of looks to us like it's straightforwardly kills you."}, {"block_idx": 6, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Like, why would you even expect that not to happen?"}, {"block_idx": 7, "token_num": 3, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "That's us."}, {"block_idx": 8, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And other people are going like, there is no danger here."}, {"block_idx": 9, "token_num": 4, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "This is ridiculous."}, {"block_idx": 10, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "The people talking about it are stupid."}, {"block_idx": 11, "token_num": 81, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And, you know, from a political standpoint, I think what you ought to do at least then is start getting, start getting started on preserving the option of shutting it down, which is easier to do, which would have been easier to do in 2022 than 2024 and will be easier to do in 2025 than in 2027 if we're still alive in 2027."}, {"block_idx": 12, "token_num": 22, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Actually, if we're not alive in 2027, it's still easier to do it in 2025."}, {"block_idx": 13, "token_num": 28, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "One thing that I will agree with is thinking about these things is worthwhile and you know, to have nobody thinking about it is a mistake."}, {"block_idx": 14, "token_num": 22, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "You know, if there is a a high risk, nobody thinking about it is a is the wrong thing."}, {"block_idx": 15, "token_num": 26, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "People who think about this for a while do tend to assume to do tend to start agreeing that the default outcome is everybody dying."}, {"block_idx": 16, "token_num": 23, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Sometimes they think they have clever plans for preventing that, but they do tend to follow along with the default outcome."}, {"block_idx": 17, "token_num": 4, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Is everybody dead?"}, {"block_idx": 18, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "See."}, {"block_idx": 19, "token_num": 17, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "See, I think though, unfortunately, there are many selection effects at work here."}, {"block_idx": 20, "token_num": 25, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I mean, you know, many of us, You know, I will say that I am intrinsically an optimist."}, {"block_idx": 21, "token_num": 12, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I, I don't know what how you feel about yourself."}, {"block_idx": 22, "token_num": 14, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Are you intrinsically an optimist or a pessimist or I?"}, {"block_idx": 23, "token_num": 25, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Try to, I try to do the, you know, like the best calibrated, best discriminating probabilities I can manage."}, {"block_idx": 24, "token_num": 29, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "If you, I think if you explicitly say that you're being an optimist or a pessimist, you have clearly departed the way of truth."}, {"block_idx": 25, "token_num": 18, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "You have confessed that you are now taking considerations other than truth into account in your statements."}, {"block_idx": 26, "token_num": 9, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "How sinful, how unvirtuous."}, {"block_idx": 27, "token_num": 15, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Well, for me, you know, what do I mean by that?"}, {"block_idx": 28, "token_num": 21, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I mean, I tried to do projects that many people would say, oh, that's an impossible project."}, {"block_idx": 29, "token_num": 11, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "The fact that there's not a matter of truth there."}, {"block_idx": 30, "token_num": 46, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "It's like this project is hard, but I'm going to be optimistic that it's possible rather than so, you know, I, I think that that's to say, you know, I don't do projects which I think are obviously doomed."}, {"block_idx": 31, "token_num": 15, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "But on the other hand, I'm going to take the point of view."}, {"block_idx": 32, "token_num": 16, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Let me try it rather than, oh gosh, it's never going to work."}, {"block_idx": 33, "token_num": 6, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Let me not try it."}, {"block_idx": 34, "token_num": 10, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "So that that's that's kind of what I mean."}, {"block_idx": 35, "token_num": 21, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "That is absolutely how I spent the years from like 2001 to 2021 or thereabouts."}, {"block_idx": 36, "token_num": 25, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Well, 2020 maybe was, you know, like, all right, I'm going to run at the alignment problem."}, {"block_idx": 37, "token_num": 19, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "But it became kind of clear that, you know, this wasn't going to work for me."}, {"block_idx": 38, "token_num": 14, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "It wasn't going to work for the other people people working on it."}, {"block_idx": 39, "token_num": 32, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And that the field itself had kind of like failed to form a process that could distinguish that that that we're we're about that could like publicly distinguish Elon Musk's."}, {"block_idx": 40, "token_num": 10, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "We will just make grokked pursue truth."}, {"block_idx": 41, "token_num": 22, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And like even the old science fiction writers understood that humans may not be the most efficient way of producing truths."}, {"block_idx": 42, "token_num": 22, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Anything that just produces lots of truths may not produce other things of, you know, the best possible value."}, {"block_idx": 43, "token_num": 14, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "But you know, like who tells Elon this, that he believes?"}, {"block_idx": 44, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And yes, there's selection effects."}, {"block_idx": 45, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Like people did in fact pay me to work on this problem."}, {"block_idx": 46, "token_num": 26, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And you know, you're, you're hearing me because people paid me to work on this problem and they didn't just like starve."}, {"block_idx": 47, "token_num": 41, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And the people who founded OpenAI were people selected to believe that alignment was totally a problem within their grasp or, and, or to be willing to just take Elon Musk's money and run with it."}, {"block_idx": 48, "token_num": 43, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And if you want to look for people who are not selected, I think you end up with Geoffrey Hinton, you know, the guy who just won the Nobel Prize for the work he did on machine learning."}, {"block_idx": 49, "token_num": 16, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Then it, you know, it's kicking off the whole modern deep learning revolution."}, {"block_idx": 50, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "That's the guy who isn't obviously selected."}, {"block_idx": 51, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "That's the guy saying like, well, personally 50%."}, {"block_idx": 52, "token_num": 53, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "But if I take into account other people are saying 10 to 20%, I really need to actually sit down and talk with him at some point, which we've never actually done, and try to talk him out out out of listening to those particular other people."}, {"block_idx": 53, "token_num": 9, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "I think their arguments are making no sense."}, {"block_idx": 54, "token_num": 38, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "You know, it really, it damages my thinking about this that the various people you mentioned, you know, I've, I've, I've known all these people sometimes for a very long time."}, {"block_idx": 55, "token_num": 52, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "So it's kind of it it, it kind of throws a wrench in my kind of, you know, there is, there is sort of, you know, none of us have, I think, you know, perfect sort of calibrated rationality about everything."}, {"block_idx": 56, "token_num": 41, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And it's it's kind of, you know, it, it's always challenging to, you know, this, this thing about, you know, I consider myself a convincible person in terms of your argument."}, {"block_idx": 57, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "OK."}, {"block_idx": 58, "token_num": 32, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I'm not, you know, I don't have a, you know, I'm not about to say, oh, you know, I'm going to change my life."}, {"block_idx": 59, "token_num": 3, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "You're right."}, {"block_idx": 60, "token_num": 4, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Without understanding it."}, {"block_idx": 61, "token_num": 10, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "But I'm I'm convincible, so I'm not."}, {"block_idx": 62, "token_num": 9, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And I don't know how many people are."}, {"block_idx": 63, "token_num": 15, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Maybe there are many people who are not, but I think I am."}, {"block_idx": 64, "token_num": 27, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I'm not convinced yet, but that's, you know, I mean, like this conversation, I understand much more about what you're saying."}, {"block_idx": 65, "token_num": 30, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And it's, you know, I think there are, to me, there are interesting questions to try to answer, which people should try and answer."}, {"block_idx": 66, "token_num": 11, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I mean, you make it sound like it's urgent."}, {"block_idx": 67, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "You know, the people are coming off the ships and, and you might be right."}, {"block_idx": 68, "token_num": 6, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "You might be right and."}, {"block_idx": 69, "token_num": 46, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "I mean, I'm, I'm watching things go downhill in terms of how much you'd have to spend and how much pain it would take to get to like de proliferate the technology and, you know, it would have been easier."}, {"block_idx": 70, "token_num": 6, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I don't think it's realistic."}, {"block_idx": 71, "token_num": 4, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I don't think."}, {"block_idx": 72, "token_num": 15, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "It would cost less than the Persian Gulf War if we did it today."}, {"block_idx": 73, "token_num": 23, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And even if we like, and if we do it later, maybe it costs more like World War 2."}, {"block_idx": 74, "token_num": 18, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "But humanity did not lie down and die when the alternative was fighting World War 2."}, {"block_idx": 75, "token_num": 10, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "We went off and fought World War 2."}, {"block_idx": 76, "token_num": 16, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And if everybody's going to die otherwise, you just do what it takes."}, {"block_idx": 77, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Yeah."}, {"block_idx": 78, "token_num": 27, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "But the fact is there are things that one can de proliferate like nuclear weapons for example, because the supply chain is really complicated."}, {"block_idx": 79, "token_num": 4, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "There are ideas."}, {"block_idx": 80, "token_num": 11, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "It's very hard to deproliferate ideas."}, {"block_idx": 81, "token_num": 53, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Yep, If it if, if it were the case that a single person on earth having the idea in their mind of artificial superintelligence would cause everyone to die, that would be an even worse situation to be in than the one we are in right now."}, {"block_idx": 82, "token_num": 23, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "I might in that case, well, despair or like try to do something like weirder and sillier."}, {"block_idx": 83, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "I don't think we're in that situation."}, {"block_idx": 84, "token_num": 15, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "I don't think we'd we'd need to deproliferate the idea."}, {"block_idx": 85, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "OK."}, {"block_idx": 86, "token_num": 9, "speaker_id": "speaker_3", "speaker_name": "Host", "text": "Gentlemen, thank you so much."}, {"block_idx": 87, "token_num": 11, "speaker_id": "speaker_3", "speaker_name": "Host", "text": "I, I, I'm going to call it now."}, {"block_idx": 88, "token_num": 13, "speaker_id": "speaker_3", "speaker_name": "Host", "text": "I think this might be the best conversation in MLST history."}, {"block_idx": 89, "token_num": 2, "speaker_id": "speaker_3", "speaker_name": "Host", "text": "Thanks."}, {"block_idx": 90, "token_num": 72, "speaker_id": "speaker_3", "speaker_name": "Host", "text": "And part of that and our purpose is about curating conversations of this quality level with people of your, you know, Calibre And I, I was expecting this to be a bit of a kind of, I don't want to say ChatGPT conversation, but talking past each other and the, the authentic exchange that you both just had is really mind blowing."}, {"block_idx": 91, "token_num": 6, "speaker_id": "speaker_3", "speaker_name": "Host", "text": "So thank you so much."}, {"block_idx": 92, "token_num": 3, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Thank you."}, {"block_idx": 93, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Thanks."}, {"block_idx": 94, "token_num": 6, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Thanks for setting it up."}, {"block_idx": 95, "token_num": 4, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "This was interesting."}, {"block_idx": 96, "token_num": 9, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Eliezer, nice to see you."}, {"block_idx": 97, "token_num": 20, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Hopefully we'll, I think it's been like 15 years since we we saw each other in person."}, {"block_idx": 98, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "See you in another 15 years?"}, {"block_idx": 99, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "So you in another 15 years?"}, {"block_idx": 100, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "No, I, I, I, I could."}, {"block_idx": 101, "token_num": 4, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "I could although."}, {"block_idx": 102, "token_num": 10, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "15 years according to you, it's all over."}, {"block_idx": 103, "token_num": 26, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Well, well, yeah, but I'll, but I'll like, it would be great to still be around in 15 years."}, {"block_idx": 104, "token_num": 21, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "But that said, I'm, I'm not saying that we like shouldn't talk again for another 15 years."}, {"block_idx": 105, "token_num": 14, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "I'm not saying this was the optimal interval or anything, you know?"}, {"block_idx": 106, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Yeah."}, {"block_idx": 107, "token_num": 6, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Right, right, right."}, {"block_idx": 108, "token_num": 14, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And we both, I think are interested in cryonics and things."}, {"block_idx": 109, "token_num": 24, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And maybe we get to talk in 300 years and we get to say, you know, this was the we."}, {"block_idx": 110, "token_num": 3, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Got to."}, {"block_idx": 111, "token_num": 36, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "We got to resolve all the bets if we make it through there, though, you know, conditioning on that possibility, probably you won a bunch of arguments, right, Right."}]}