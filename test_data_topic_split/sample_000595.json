{"sample_idx": 11, "start_block_idx": 1106, "last_block_idx": 1222, "block_list": [{"block_idx": 0, "token_num": 16, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Could you show the AI system these two responses and ask which response is better?"}, {"block_idx": 1, "token_num": 13, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And then second, well, what criterion should the AI use?"}, {"block_idx": 2, "token_num": 34, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And so then there's this idea, you have a single document, a constitution if you will, that says, these are the principles the model should be using to respond."}, {"block_idx": 3, "token_num": 18, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And the AI system reads those reads principles as well as reading the environment and the response."}, {"block_idx": 4, "token_num": 15, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And it says, “Well, how good did the AI model do?”"}, {"block_idx": 5, "token_num": 8, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "It's basically a form of self-play."}, {"block_idx": 6, "token_num": 7, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "You're training the model against itself."}, {"block_idx": 7, "token_num": 31, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And so the AI gives the response and then you feed that back into what's called the preference model, which in turn feeds the model to make it better."}, {"block_idx": 8, "token_num": 21, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So you have this triangle of the AI, the preference model, and the improvement of the AI itself."}, {"block_idx": 9, "token_num": 18, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "And we should say that in the constitution, the set of principles are human interpretable."}, {"block_idx": 10, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "They're-"}, {"block_idx": 11, "token_num": 2, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Yeah."}, {"block_idx": 12, "token_num": 2, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Yeah."}, {"block_idx": 13, "token_num": 12, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "It's something both the human and the AI system can read."}, {"block_idx": 14, "token_num": 11, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So it has this nice translatability or symmetry."}, {"block_idx": 15, "token_num": 23, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "In practice, we both use a model constitution and we use RLHF and we use some of these other methods."}, {"block_idx": 16, "token_num": 33, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So it's turned into one tool in a toolkit, that both reduces the need for RLHF and increases the value we get from using each data point of RLHF."}, {"block_idx": 17, "token_num": 13, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "It also interacts in interesting ways with future reasoning type RL methods."}, {"block_idx": 18, "token_num": 18, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So it's one tool in the toolkit, but I think it is a very important tool."}, {"block_idx": 19, "token_num": 10, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Well, it's a compelling one to us humans."}, {"block_idx": 20, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Thinking about the founding fathers and the founding of the United States."}, {"block_idx": 21, "token_num": 25, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "The natural question is who and how do you think it gets to define the constitution, the set of principles in the constitution?"}, {"block_idx": 22, "token_num": 2, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Yeah."}, {"block_idx": 23, "token_num": 12, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So I'll give a practical answer and a more abstract answer."}, {"block_idx": 24, "token_num": 20, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I think the practical answer is look in practice, models get used by all kinds of different customers."}, {"block_idx": 25, "token_num": 17, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And so you can have this idea where the model can have specialized rules or principles."}, {"block_idx": 26, "token_num": 8, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "We fine tune versions of models implicitly."}, {"block_idx": 27, "token_num": 17, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "We've talked about doing it explicitly having special principles that people can build into the models."}, {"block_idx": 28, "token_num": 16, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So from a practical perspective, the answer can be very different from different people."}, {"block_idx": 29, "token_num": 16, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "A customer service agent behaves very differently from a lawyer and obeys different principles."}, {"block_idx": 30, "token_num": 20, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "But, I think at the base of it, there are specific principles that models have to obey."}, {"block_idx": 31, "token_num": 14, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I think a lot of them are things that people would agree with."}, {"block_idx": 32, "token_num": 15, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Everyone agrees that we don't want models to present these CBRN risks."}, {"block_idx": 33, "token_num": 22, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I think we can go a little further and agree with some basic principles of democracy and the rule of law."}, {"block_idx": 34, "token_num": 51, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Beyond that, it gets very uncertain and there our goal is generally for the models to be more neutral, to not espouse a particular point of view and more just be wise agents or advisors that will help you think things through and will present possible considerations."}, {"block_idx": 35, "token_num": 8, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "But don't express strong or specific opinions."}, {"block_idx": 36, "token_num": 32, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "OpenAI released a model spec where it clearly, concretely defines some of the goals of the model and specific examples like AB, how the model should behave."}, {"block_idx": 37, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Do you find that interesting?"}, {"block_idx": 38, "token_num": 20, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "By the way I should mention, I believe the brilliant John Schulman was a part of that."}, {"block_idx": 39, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "He's now at Anthropic."}, {"block_idx": 40, "token_num": 9, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Do you think this is a useful direction?"}, {"block_idx": 41, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Might Anthropic release a model spec as well?"}, {"block_idx": 42, "token_num": 2, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Yeah."}, {"block_idx": 43, "token_num": 9, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So I think that's a pretty useful direction."}, {"block_idx": 44, "token_num": 12, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Again, it has a lot in common with constitutional AI."}, {"block_idx": 45, "token_num": 12, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So again, another example of a race to the top."}, {"block_idx": 46, "token_num": 16, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "We have something that we think a better and more responsible way of doing things."}, {"block_idx": 47, "token_num": 6, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "It's also a competitive advantage."}, {"block_idx": 48, "token_num": 15, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Then others discover that it has advantages and then start to do that thing."}, {"block_idx": 49, "token_num": 29, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "We then no longer have the competitive advantage, but it's good from the perspective that now everyone has adopted a positive practice that others were not adopting."}, {"block_idx": 50, "token_num": 28, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And so our response to that is, “Well, looks like we need a new competitive advantage in order to keep driving this race upwards.”"}, {"block_idx": 51, "token_num": 9, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So that's how I generally feel about that."}, {"block_idx": 52, "token_num": 11, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I also think every implementation of these things is different."}, {"block_idx": 53, "token_num": 31, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So there were some things in the model spec that were not in constitutional AI, and so we can always adopt those things or at least learn from them."}, {"block_idx": 54, "token_num": 25, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "So again, I think this is an example of the positive dynamic that I think we should all want the field to have."}, {"block_idx": 55, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Let's talk about the incredible essay Machines of Loving Grace."}, {"block_idx": 56, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "I recommend everybody read it."}, {"block_idx": 57, "token_num": 5, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "It's a long one."}, {"block_idx": 58, "token_num": 5, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "It is rather long."}, {"block_idx": 59, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Yeah."}, {"block_idx": 60, "token_num": 15, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "It's really refreshing to read concrete ideas about what a positive future looks like."}, {"block_idx": 61, "token_num": 23, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "And you took a bold stance because it's very possible that you might be wrong on the dates or the specific applications-"}, {"block_idx": 62, "token_num": 4, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Oh, yeah."}, {"block_idx": 63, "token_num": 14, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I'm fully expecting to well, definitely be wrong about all the details."}, {"block_idx": 64, "token_num": 20, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I might be just spectacularly wrong about the whole thing and people will laugh at me for years."}, {"block_idx": 65, "token_num": 7, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "That's just how the future works."}, {"block_idx": 66, "token_num": 58, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So you provided a bunch of concrete positive impacts of AI and how exactly a super intelligent AI might accelerate the rate of breakthroughs in, for example, biology and chemistry, that would then lead to things like we cure most cancers, prevent all infectious disease, double the human lifespan and so on."}, {"block_idx": 67, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So let's talk about this essay first."}, {"block_idx": 68, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Can you give a high-level vision of this essay?"}, {"block_idx": 69, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "And what are the key takeaways that people have?"}, {"block_idx": 70, "token_num": 2, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Yeah."}, {"block_idx": 71, "token_num": 28, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I have spent a lot of time, and in Anthropic has spent a lot of effort on how do we address the risks of AI?"}, {"block_idx": 72, "token_num": 8, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "How do we think about those risks?"}, {"block_idx": 73, "token_num": 25, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "We're trying to do a race to the top, what that requires us to build all these capabilities and the capabilities are cool."}, {"block_idx": 74, "token_num": 16, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "But, a big part of what we're trying to do is address the risks."}, {"block_idx": 75, "token_num": 23, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And the justification for that is like, well, all these positive things, the market is this very healthy organism."}, {"block_idx": 76, "token_num": 9, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "It's going to produce all the positive things."}, {"block_idx": 77, "token_num": 3, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "The risks?"}, {"block_idx": 78, "token_num": 13, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I don't know, we might mitigate them, we might not."}, {"block_idx": 79, "token_num": 14, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And so we can have more impact by trying to mitigate the risks."}, {"block_idx": 80, "token_num": 26, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "But, I noticed that one flaw in that way of thinking, and it's not a change in how seriously I take the risks."}, {"block_idx": 81, "token_num": 31, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "It's maybe a change in how I talk about them, is that no matter how logical or rational, that line of reasoning that I just gave might be."}, {"block_idx": 82, "token_num": 14, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "If you only talk about risks, your brain only thinks about risks."}, {"block_idx": 83, "token_num": 19, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And so, I think it's actually very important to understand, what if things do go well?"}, {"block_idx": 84, "token_num": 27, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And the whole reason we're trying to prevent these risks is not because we're afraid of technology, not because we want to slow it down."}, {"block_idx": 85, "token_num": 47, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "It's because if we can get to the other side of these risks, if we can run the gauntlet successfully, to put it in stark terms, then on the other side of the gauntlet are all these great things."}, {"block_idx": 86, "token_num": 8, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And these things are worth fighting for."}, {"block_idx": 87, "token_num": 8, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And these things can really inspire people."}, {"block_idx": 88, "token_num": 34, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And I think I imagine, because … Look, you have all these investors, all these VCs, all these AI companies talking about all the positive benefits of AI."}, {"block_idx": 89, "token_num": 9, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "But as you point out, it's weird."}, {"block_idx": 90, "token_num": 12, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "There's actually a dearth of really getting specific about it."}, {"block_idx": 91, "token_num": 34, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "There's a lot of random people on Twitter posting these gleaming cities and this just vibe of grind, accelerate harder, kick out the … It's just this very aggressive ideological."}, {"block_idx": 92, "token_num": 15, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "But then you're like, “Well, what are you actually excited about?”"}, {"block_idx": 93, "token_num": 48, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And so, I figured that I think it would be interesting and valuable for someone who's actually coming from the risk side to try and really make a try at explaining what the benefits are, both because I think it's something we can all get behind"}, {"block_idx": 94, "token_num": 7, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "and I want people to understand."}, {"block_idx": 95, "token_num": 16, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I want them to really understand that this isn't Doomers versus Accelerationists."}, {"block_idx": 96, "token_num": 55, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "This is that, if you have a true understanding of where things are going with AI, and maybe that's the more important axis, AI is moving fast versus AI is not moving fast, then you really appreciate the benefits and you really want humanity or civilization to seize those benefits."}, {"block_idx": 97, "token_num": 14, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "But, you also get very serious about anything that could derail them."}, {"block_idx": 98, "token_num": 51, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So I think the starting point is to talk about what this Powerful AI, which is the term you like to use, most of the world uses AGI, but you don't like the term, because it's basically has too much baggage, it's become meaningless."}, {"block_idx": 99, "token_num": 14, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "It's like we're stuck with the terms whether we like them or not."}, {"block_idx": 100, "token_num": 15, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "Maybe we're stuck with the terms and my efforts to change them are futile."}, {"block_idx": 101, "token_num": 3, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "It's admirable."}, {"block_idx": 102, "token_num": 8, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I'll tell you what else I don't …"}, {"block_idx": 103, "token_num": 14, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "This is a pointless semantic point, but I keep talking about it-"}, {"block_idx": 104, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "It's back to naming again."}, {"block_idx": 105, "token_num": 9, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I'm just going to do it once more."}, {"block_idx": 106, "token_num": 25, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "I think it's a little like, let's say it was like 1995 and Moore's law is making the computers faster."}, {"block_idx": 107, "token_num": 27, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And for some reason there had been this verbal tick that everyone was like, “Well, someday we're going to have supercomputers."}, {"block_idx": 108, "token_num": 39, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And supercomputers are going to be able to do all these things that … Once we have supercomputers, we'll be able to sequence the genome, we'll be able to do other things.”"}, {"block_idx": 109, "token_num": 3, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And so."}, {"block_idx": 110, "token_num": 28, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "One, it's true, the computers are getting faster and as they get faster, they're going to be able to do all these great things."}, {"block_idx": 111, "token_num": 20, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "But there's, there's no discrete point at which you had a supercomputer and previous computers were no."}, {"block_idx": 112, "token_num": 28, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "“Supercomputer” is a term we use, but it's a vague term to just describe computers that are faster than what we have today."}, {"block_idx": 113, "token_num": 19, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "There's no point at which you pass the threshold and you're like, “Oh, my God!"}, {"block_idx": 114, "token_num": 11, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "We're doing a totally new type of computation and new …"}, {"block_idx": 115, "token_num": 10, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "And so I feel that way about AGI."}, {"block_idx": 116, "token_num": 6, "speaker_id": "speaker_0", "speaker_name": "Dario Amodei", "text": "There's just a smooth exponential."}]}