{"sample_idx": 4, "start_block_idx": 405, "last_block_idx": 502, "block_list": [{"block_idx": 0, "token_num": 27, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Like if you look at a lot of the other Frontier models, one qualm I have is it feels like they're not necessarily over."}, {"block_idx": 1, "token_num": 28, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "I'm not saying they they train on benchmarks, but they perform really well on benchmarks relative to kind of everything that's kind of in the middle."}, {"block_idx": 2, "token_num": 30, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So if you tried in all these benchmarks and things that are in the distribution of the benchmarks they're evaluated on, you know, they'll do really well."}, {"block_idx": 3, "token_num": 59, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "But when you push them a little bit outside of that sonnets, I think the one that that kind of does best at, at at kind of maintaining that same capability, like you kind of have the same capability in the benchmark as when you try to instruct it to do anything with coding."}, {"block_idx": 4, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "What?"}, {"block_idx": 5, "token_num": 16, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Another ridiculous question is the difference between the normal programming experience versus what benchmarks represent."}, {"block_idx": 6, "token_num": 17, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Like where do benchmarks fall short, do you think, when we're evaluating these models?"}, {"block_idx": 7, "token_num": 41, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "By the way, that's like a really, really hard, it's like like critically important detail, like how how different like benchmarks are versus versus like real coding, where real coding it's not interview style coding."}, {"block_idx": 8, "token_num": 19, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "It's you're, you're doing these, you know, humans are saying like half broken English sometimes."}, {"block_idx": 9, "token_num": 14, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "And sometimes you're saying like, oh, do what I did before."}, {"block_idx": 10, "token_num": 26, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "Sometimes you're saying, you know, go at this thing and then do this other thing for me and then make this UI element."}, {"block_idx": 11, "token_num": 20, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "And then, you know, it's it's just like a lot of things are sort of context dependent."}, {"block_idx": 12, "token_num": 23, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "You really want to like understand the human and then do do what the human wants as opposed to sort of this."}, {"block_idx": 13, "token_num": 21, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "Maybe the the way to put it is sort of abstractly is the interview problems are very well specified."}, {"block_idx": 14, "token_num": 15, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "They've lean a lot on specification while the human stuff is less specified."}, {"block_idx": 15, "token_num": 57, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "Yeah, I think of this this benchmark question is both complicated by what Sualeh just mentioned and then also to what Aman was getting into is that even if you like you know, there's this problem of like the skew between what can you actually model in a benchmark versus real programming."}, {"block_idx": 16, "token_num": 20, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And that can be sometimes hard to encapsulate because it's like real programming is like very messy and."}, {"block_idx": 17, "token_num": 12, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "Sometimes things aren't super well specified what's correct or what isn't."}, {"block_idx": 18, "token_num": 14, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "But then it's also doubly hard because of this public benchmark problem."}, {"block_idx": 19, "token_num": 35, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And that's both because public benchmarks are sometimes kind of hill climbed on, then it's like really, really hard to also get the data from the public benchmarks out of the models."}, {"block_idx": 20, "token_num": 30, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And so for instance, like one of the most popular like agent benchmarks suite bench is really, really contaminated and the training data of these foundation models."}, {"block_idx": 21, "token_num": 27, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And so if you ask these foundation models to do a sweet bench problem, you actually don't give them the context of a code base."}, {"block_idx": 22, "token_num": 19, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "They can like hallucinate the right file paths, they can hallucinate the right function names."}, {"block_idx": 23, "token_num": 19, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And so the, the it's, it's also just the public aspect of these things is tricky."}, {"block_idx": 24, "token_num": 61, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Yeah, like in that case, it could be trained on the literal issues or pull requests themselves and and maybe the labs will start to do a better job or they've already done a good job at decontaminating those things, but they're not going to emit the actual training data of the repository itself."}, {"block_idx": 25, "token_num": 20, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Like these are all like some of the most popular Python repositories, like SymPy is one example."}, {"block_idx": 26, "token_num": 29, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "I don't think they're going to handicap their models on SymPy and all these popular Python repositories in order to get true evaluation scores in these benchmarks."}, {"block_idx": 27, "token_num": 47, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "I think that given the dearth of benchmarks, there have been like a few interesting crutches that places that build systems with these models or build these models actually use to get a sense of are they going the right direction or not."}, {"block_idx": 28, "token_num": 23, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And in a lot of places people will actually just have humans play with the things and give qualitative feedback on these."}, {"block_idx": 29, "token_num": 10, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "Like one or two of the foundation model companies."}, {"block_idx": 30, "token_num": 16, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "They, they have people who that's, that's a big part of their role."}, {"block_idx": 31, "token_num": 35, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And, you know, internally we also, you know, qualitatively assess these models and actually lean on that a lot in addition to like private evals that we have."}, {"block_idx": 32, "token_num": 5, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "It's like the vibe."}, {"block_idx": 33, "token_num": 5, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "The vibe, yeah."}, {"block_idx": 34, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "The vibe, the vibe."}, {"block_idx": 35, "token_num": 5, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Benchmark, Human benchmark."}, {"block_idx": 36, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "You pull in the humans to do a vibe check, yeah."}, {"block_idx": 37, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "OK."}, {"block_idx": 38, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "I mean, that's, that's kind of what I do."}, {"block_idx": 39, "token_num": 43, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Like just like reading online forums and Reddit and X just like, well, I don't know how to properly load in people's opinions because they'll say things like I feel like Claude or GPT has gotten Dumber or something."}, {"block_idx": 40, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "They'll say I feel like."}, {"block_idx": 41, "token_num": 20, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "And then I sometimes feel like that too, but I wonder if it's the models problem or mine."}, {"block_idx": 42, "token_num": 32, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "You know, with Claude, there's an interesting take I heard where I think AWS has different chips and I I suspect they've slightly different numerics than NVIDIA GPUs."}, {"block_idx": 43, "token_num": 36, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And someone speculated that Claude's degraded performance had to do with maybe using the quantized version that existed on AWS Bedrock versus whatever was running on on Anthropic's GPUs."}, {"block_idx": 44, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "I interview a bunch of people who have conspiracy theories."}, {"block_idx": 45, "token_num": 5, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "I'm glad you spoke."}, {"block_idx": 46, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "You spoke to this conspiracy well."}, {"block_idx": 47, "token_num": 67, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "It's, it's, it's not not like conspiracy theory as much as they're just, they're like they're, you know, humans, humans are humans and there's, there's these details and you know, you're doing like this crazy amount of flops and, you know, chips are messy and man, you can just have bugs like bugs are."}, {"block_idx": 48, "token_num": 13, "speaker_id": "speaker_5", "speaker_name": "Sualeh Asif", "text": "It's it's hard to overstate how hard bugs are to avoid."}, {"block_idx": 49, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "What's the role of a good prompt in all this?"}, {"block_idx": 50, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "You mentioned that benchmarks have really structured, well formulated prompts."}, {"block_idx": 51, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "What What should a human be doing to maximize success?"}, {"block_idx": 52, "token_num": 9, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "And what's the importance of what the humans?"}, {"block_idx": 53, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "You wrote a blog post on?"}, {"block_idx": 54, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "You called it prompt design."}, {"block_idx": 55, "token_num": 12, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "Yeah, I think it depends on which model you're using."}, {"block_idx": 56, "token_num": 15, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And all of them are slightly different and they respond differently to different prompts."}, {"block_idx": 57, "token_num": 27, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "But I think the original GPT-4 and the original sort of GPT models last last year, they were quite sensitive to the prompts."}, {"block_idx": 58, "token_num": 9, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "They also had a very small context window."}, {"block_idx": 59, "token_num": 22, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And so we all of these pieces of information around the codebase that would maybe be relevant in the prompt."}, {"block_idx": 60, "token_num": 20, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "Like you have the docs, you have the files that you add, you have the conversation history."}, {"block_idx": 61, "token_num": 18, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And then there's a problem like how do you decide what you actually put in the prompt?"}, {"block_idx": 62, "token_num": 31, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And when you have a limited space And even for today's models, even when you have long context, filling out the entire context window means that it's slower."}, {"block_idx": 63, "token_num": 18, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "It means that sometimes the model actually gets confused and some models get more confused than others."}, {"block_idx": 64, "token_num": 23, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And we have this one system internally that we call PreAmble, which helps us with that a little bit."}, {"block_idx": 65, "token_num": 20, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And I think it was built for the era before where we had 8000 token context windows."}, {"block_idx": 66, "token_num": 47, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And it's a little bit similar to when you're making a website, you, you sort of you, you want it to work on mobile, you wanted to work on a desktop screen and you have this dynamic information which you don't have."}, {"block_idx": 67, "token_num": 26, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "For example, if you're making you like designing a print magazine, you have like, you know exactly where you can put stuff."}, {"block_idx": 68, "token_num": 45, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "But when you have a website or when you have a prompt, you have these inputs and then you need to format them to always work, even if the input is really big, then you might have to cut something down."}, {"block_idx": 69, "token_num": 18, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And, and, and so the idea was OK, like, let's take some inspiration."}, {"block_idx": 70, "token_num": 8, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "What's the best way to design websites?"}, {"block_idx": 71, "token_num": 39, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "Well, the thing that we really like is is React and the declarative approach where you, you use JSX in, in, in JavaScript and then you declare this is what I want."}, {"block_idx": 72, "token_num": 18, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And I think this has higher priority or like this has higher Z index than something else."}, {"block_idx": 73, "token_num": 11, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And then you have this rendering engine in web design."}, {"block_idx": 74, "token_num": 6, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "It's, it's like Chrome."}, {"block_idx": 75, "token_num": 19, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And in our case, it's a PreAmble renderer which then fits everything onto the page."}, {"block_idx": 76, "token_num": 21, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And as you declare it, it would decide what you want and then it figures out what you want."}, {"block_idx": 77, "token_num": 11, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And as we have found that to be quite helpful."}, {"block_idx": 78, "token_num": 15, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And I think the role of it has has sort of shifted over time."}, {"block_idx": 79, "token_num": 39, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "Where initially was to fit to these small context windows, now it's really useful because you know, it helps us with splitting up the data that goes into the prompt and the actual rendering of it."}, {"block_idx": 80, "token_num": 34, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And so it's easier to debug because you can change the rendering of the prompt and then try it on old prompts because you have the raw data that went into their prompt."}, {"block_idx": 81, "token_num": 6, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And then you can see."}, {"block_idx": 82, "token_num": 14, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "Did my change actually improve it for for like this entire eval set?"}, {"block_idx": 83, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So do you literally prompt with JSX?"}, {"block_idx": 84, "token_num": 4, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "Yes, yes."}, {"block_idx": 85, "token_num": 8, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "So it kind of looks like React."}, {"block_idx": 86, "token_num": 20, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "There are components, like we have one component that's file component and it takes in like the cursor."}, {"block_idx": 87, "token_num": 30, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "Like usually there is like one line where the cursor is in your file and that's like probably the most important line because that's the one you're looking at."}, {"block_idx": 88, "token_num": 8, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And so then you can give priorities."}, {"block_idx": 89, "token_num": 22, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "So like that line has the highest priority and then you subtract 1 for every line that is farther away."}, {"block_idx": 90, "token_num": 23, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And then eventually when it's rendered, it figure out how many lines can actually fit and it centers around that thing."}, {"block_idx": 91, "token_num": 3, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "That's amazing."}, {"block_idx": 92, "token_num": 42, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And you can do like other fancy things where if you have lots of code blocks from the entire code base you could use retrieval and things like embedding and re ranking scores to add priorities for each of these components."}, {"block_idx": 93, "token_num": 16, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So should humans when they ask questions also use try to use something like that?"}, {"block_idx": 94, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Like would it be beneficial to write JSX in the in the?"}, {"block_idx": 95, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Probably the whole idea is just should be loose and messy."}, {"block_idx": 96, "token_num": 23, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "I, I think our goal is kind of that you should just do whatever is the most natural thing for you."}, {"block_idx": 97, "token_num": 26, "speaker_id": "speaker_3", "speaker_name": "Arvid Lunnemark", "text": "And then we our job is to figure out how do we actually like retrieve the relevant thing so that you're thinking actually makes sense."}]}