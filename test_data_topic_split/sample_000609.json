{"sample_idx": 24, "start_block_idx": 2423, "last_block_idx": 2518, "block_list": [{"block_idx": 0, "token_num": 5, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I think it's feasible."}, {"block_idx": 1, "token_num": 7, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I have wondered the same thing."}, {"block_idx": 2, "token_num": 23, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Not only that, I could actually just see that happening eventually, where it's just like the model ended the chat."}, {"block_idx": 3, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Do you know how harsh that could be for some people?"}, {"block_idx": 4, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "But it might be necessary."}, {"block_idx": 5, "token_num": 9, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Yeah, it feels very extreme or something."}, {"block_idx": 6, "token_num": 22, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "The only time I've ever really thought this is, I think that there was a… I'm trying to remember."}, {"block_idx": 7, "token_num": 26, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "This was possibly a while ago, but where someone just left this thing, maybe it was an automated thing, interacting with Claude."}, {"block_idx": 8, "token_num": 9, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And Claude's getting more and more frustrated-"}, {"block_idx": 9, "token_num": 4, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Yeah, just-"}, {"block_idx": 10, "token_num": 35, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "… and like, “Why are we having…” I wished that Claude could have just been like, “I think that an error has happened and you've left this thing running."}, {"block_idx": 11, "token_num": 8, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "What if I just stopped talking now?"}, {"block_idx": 12, "token_num": 17, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And if you want me to start talking again, actively tell me or do something.”"}, {"block_idx": 13, "token_num": 4, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "It is harsh."}, {"block_idx": 14, "token_num": 20, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I'd feel really sad if I was chatting with Claude and Claude just was like, “I'm done.”"}, {"block_idx": 15, "token_num": 23, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "That would be a special Turing Test moment, where Claude says, “I need a break for an hour."}, {"block_idx": 16, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "And it sounds like you do too.”"}, {"block_idx": 17, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "And just leave, close the window."}, {"block_idx": 18, "token_num": 10, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Obviously, it doesn't have a concept of time."}, {"block_idx": 19, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Right."}, {"block_idx": 20, "token_num": 17, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "But you can easily… I could make that right now, and the model just…"}, {"block_idx": 21, "token_num": 22, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I could just be like, oh, here's the circumstances in which you can just say the conversation is done."}, {"block_idx": 22, "token_num": 23, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Because you can get the models to be pretty responsive to prompts, you could even make it a fairly high bar."}, {"block_idx": 23, "token_num": 27, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "It could be like, if the human doesn't interest you or do things that you find intriguing and you're bored, you can just leave."}, {"block_idx": 24, "token_num": 14, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I think that it would be interesting to see where Claude utilized it."}, {"block_idx": 25, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Yeah."}, {"block_idx": 26, "token_num": 29, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "But I think sometimes it should be like, oh, this programming task is getting super boring, so either we talk about, I don't know…"}, {"block_idx": 27, "token_num": 7, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "… task is getting super boring."}, {"block_idx": 28, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "So, I don't know, either we talk about fun things now, or I'm done."}, {"block_idx": 29, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Yeah."}, {"block_idx": 30, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "It actually is inspiring me to add that to the user prompt."}, {"block_idx": 31, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Okay."}, {"block_idx": 32, "token_num": 22, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "The movie Her, do you think we'll be headed there one day where humans have romantic relationships with AI systems?"}, {"block_idx": 33, "token_num": 10, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "In this case it's just text and voice-based."}, {"block_idx": 34, "token_num": 31, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I think that we're going to have to navigate a hard question of relationships with AIs, especially if they can remember things about your past interactions with them."}, {"block_idx": 35, "token_num": 33, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I'm of many minds about this because I think the reflexive reaction is to be like, “This is very bad, and we should prohibit it in some way.”"}, {"block_idx": 36, "token_num": 17, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I think it's a thing that has to be handled with extreme care for many reasons."}, {"block_idx": 37, "token_num": 34, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "One is, for example, if you have the models changing like this, you probably don't want people performing long-term attachments to something that might change with the next iteration."}, {"block_idx": 38, "token_num": 93, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "At the same time, I'm like, there's probably a benign version of this where I'm like, for example, if you are unable to leave the house and you can't be talking with people at all times of the day, and this is something that you find nice to have conversations with, you like that it can remember you, and you genuinely would be sad if you couldn't talk to it anymore, there's a way in which I could see it being healthy and helpful."}, {"block_idx": 39, "token_num": 51, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "So, my guess is this is a thing that we're going to have to navigate carefully, and I think it's also… It reminds me of all of this stuff where it has to be just approached with nuance and thinking through what are the healthy options here?"}, {"block_idx": 40, "token_num": 33, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And how do you encourage people towards those while respecting their right to… If someone is like, “Hey, I get a lot out of chatting with this model."}, {"block_idx": 41, "token_num": 6, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I'm aware of the risks."}, {"block_idx": 42, "token_num": 6, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I'm aware it could change."}, {"block_idx": 43, "token_num": 27, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I don't think it's unhealthy, it's just something that I can chat to during the day,” I kind of want to just respect that."}, {"block_idx": 44, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "I personally think there'll be a lot of really close relationships."}, {"block_idx": 45, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "I don't know about romantic, but friendships at least."}, {"block_idx": 46, "token_num": 62, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "And then you have to, I mean, there's so many fascinating things there, just like you said, you have to have some kind of stability guarantees that it's not going to change, because that's the traumatic thing for us, if a close friend of ours completely changed all of a sudden with a fresh update."}, {"block_idx": 47, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Yeah."}, {"block_idx": 48, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Yeah."}, {"block_idx": 49, "token_num": 32, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So I mean, to me, that's just a fascinating exploration of a perturbation to human society that will just make us think deeply about what's meaningful to us."}, {"block_idx": 50, "token_num": 43, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I think it's also the only thing that I've thought consistently through this as maybe not necessarily a mitigation, but a thing that feels really important is that the models are always extremely accurate with the human about what they are."}, {"block_idx": 51, "token_num": 30, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "It's like a case where it's basically, if you imagine… I really like the idea of the models, say, knowing roughly how they were trained."}, {"block_idx": 52, "token_num": 9, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And I think Claude will often do this."}, {"block_idx": 53, "token_num": 38, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Part of the traits training included what Claude should do if people… Basically explaining the kind of limitations of the relationship between an AI and a human, that it doesn't retain things from the conversation."}, {"block_idx": 54, "token_num": 21, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And so I think it will just explain to you like, “Hey, I won't remember this conversation."}, {"block_idx": 55, "token_num": 6, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Here's how I was trained."}, {"block_idx": 56, "token_num": 22, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "It's unlikely that I can have a certain kind of relationship with you, and it's important that you know that."}, {"block_idx": 57, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "It's important for your mental well-being that you don't think that I'm something that I'm not.”"}, {"block_idx": 58, "token_num": 31, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And somehow I feel like this is one of the things where I'm like, “Ah, it feels like a thing that I always want to be true.”"}, {"block_idx": 59, "token_num": 48, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I don't want models to be lying to people, because if people are going to have healthy relationships with anything, it's kind of… Yeah, I think that's easier if you always just know exactly what the thing is that you are relating to."}, {"block_idx": 60, "token_num": 14, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "It doesn't solve everything, but I think it helps quite a lot."}, {"block_idx": 61, "token_num": 39, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Anthropic may be the very company to develop a system that we definitively recognize as AGI, and you very well might be the person that talks to it, probably talks to it first."}, {"block_idx": 62, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "What would the conversation contain?"}, {"block_idx": 63, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "What would be your first question?"}, {"block_idx": 64, "token_num": 13, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Well, it depends partly on the capability level of the model."}, {"block_idx": 65, "token_num": 54, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "If you have something that is capable in the same way that an extremely capable human is, I imagine myself interacting with it the same way that I do with an extremely capable human, with the one difference that I'm probably going to be trying to probe and understand its behaviors."}, {"block_idx": 66, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "But in many ways, I'm like, I can then just have useful conversations with it."}, {"block_idx": 67, "token_num": 22, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "So, if I'm working on something as part of my research, I can just be like, “Oh.”"}, {"block_idx": 68, "token_num": 9, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Which I already find myself starting to do."}, {"block_idx": 69, "token_num": 17, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "If I'm like, “Oh, I feel like there's this thing in virtue ethics."}, {"block_idx": 70, "token_num": 16, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I can't quite remember the term,” I'll use the model for things like that."}, {"block_idx": 71, "token_num": 82, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And so I can imagine that being more and more the case where you're just basically interacting with it much more like you would an incredibly smart colleague and using it for the kinds of work that you want to do as if you just had a collaborator who was like… Or the slightly horrifying thing about AI is as soon as you have one collaborator, you have 1,000 collaborators if you can manage them enough."}, {"block_idx": 72, "token_num": 16, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "But what if it's two times the smartest human on Earth on that particular discipline?"}, {"block_idx": 73, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Yeah."}, {"block_idx": 74, "token_num": 22, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "I guess you're really good at probing Claude in a way that pushes its limits, understanding where the limits are."}, {"block_idx": 75, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Yep."}, {"block_idx": 76, "token_num": 24, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So, I guess what would be a question you would ask to be like, “Yeah, this is AGI”?"}, {"block_idx": 77, "token_num": 17, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "That's really hard because it feels like it has to just be a series of questions."}, {"block_idx": 78, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "If there was just one question, you can train anything to answer one question extremely well."}, {"block_idx": 79, "token_num": 16, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "In fact, you can probably train it to answer 20 questions extremely well."}, {"block_idx": 80, "token_num": 23, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "How long would you need to be locked in a room with an AGI to know this thing is AGI?"}, {"block_idx": 81, "token_num": 19, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "It's a hard question because part of me is like, “All of this just feels continuous.”"}, {"block_idx": 82, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "If you put me in a room for five minutes, I just have high error bars."}, {"block_idx": 83, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And then it's just like, maybe it's both the probability increases and the error bar decreases."}, {"block_idx": 84, "token_num": 15, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I think things that I can actually probe the edge of human knowledge of."}, {"block_idx": 85, "token_num": 11, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "So, I think this with philosophy a little bit."}, {"block_idx": 86, "token_num": 27, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "Sometimes when I ask the models philosophy questions, I am like, “This is a question that I think no one has ever asked.”"}, {"block_idx": 87, "token_num": 13, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "It's maybe right at the edge of some literature that I know."}, {"block_idx": 88, "token_num": 40, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And the models, when they struggle with that, when they struggle to come up with a novel… I'm like, “I know that there's a novel argument here because I've just thought of it myself.”"}, {"block_idx": 89, "token_num": 54, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "So, maybe that's the thing where I'm like, “I've thought of a cool novel argument in this niche area, and I'm going to just probe you to see if you can come up with it and how much prompting it takes to get you to come up with it.”"}, {"block_idx": 90, "token_num": 37, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And I think for some of these really right at the edge of human knowledge questions, I'm like, “You could not in fact come up with the thing that I came up with.”"}, {"block_idx": 91, "token_num": 17, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I think if I just took something like that where I know a lot about an area"}, {"block_idx": 92, "token_num": 58, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "and I came up with a novel issue or a novel solution to a problem, and I gave it to a model, and it came up with that solution, that would be a pretty moving moment for me because I would be like, “This is a case where no human has ever…”"}, {"block_idx": 93, "token_num": 16, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "And obviously, you see novel solutions all the time, especially to easier problems."}, {"block_idx": 94, "token_num": 19, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "I think people overestimate that novelty isn't like… It's completely different from anything that's ever happened."}, {"block_idx": 95, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Amanda", "text": "It's just like it can be a variant of things that have happened and still be novel."}]}