{"sample_idx": 11, "start_block_idx": 1095, "last_block_idx": 1172, "block_list": [{"block_idx": 0, "token_num": 37, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "But also the field is grappling with writ large about can you get language models to a place where you can actually just have the model itself, like understand a new corpus of information."}, {"block_idx": 1, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And the most popular talked about version of this is can you make the context windows infinite?"}, {"block_idx": 2, "token_num": 22, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "Then if you make the context windows infinite, can you make the model actually pay attention to the infinite context?"}, {"block_idx": 3, "token_num": 33, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And then after you can make it pay attention to the infinite context to make it somewhat feasible to actually do it, can you then do caching for that infinite context?"}, {"block_idx": 4, "token_num": 43, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "You don't have to recompute that all the time, But there are other cool ideas that are being tried that are a little bit more analogous to fine tuning of actually learning this information in the weights of the model."}, {"block_idx": 5, "token_num": 38, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "And it might be that you actually get sort of a qualitatively different type of understanding if you do it more at the weight level than if you do it at the in context learning level."}, {"block_idx": 6, "token_num": 22, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "I think the jury's still a little bit out on how this is all going to work in the end."}, {"block_idx": 7, "token_num": 35, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "But in the interim, us as a company, we are really excited about better retrieval systems and picking the parts of the code base that are most relevant to what you're doing."}, {"block_idx": 8, "token_num": 8, "speaker_id": "speaker_2", "speaker_name": "Michael Truell", "text": "We could do that a lot better."}, {"block_idx": 9, "token_num": 19, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Like one interesting proof of concept for learning this knowledge directly in the weights is with VS Code."}, {"block_idx": 10, "token_num": 17, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So we're in a VS Code fork and VS Code, the code is all public."}, {"block_idx": 11, "token_num": 12, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So these models in pre training have seen all the code."}, {"block_idx": 12, "token_num": 10, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "They probably also seen questions and answers about it."}, {"block_idx": 13, "token_num": 25, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And then they've been fine-tuned and RLHF'd to be able to be able to answer questions about code in general."}, {"block_idx": 14, "token_num": 33, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So when you ask it a question about VS Code, you know, sometimes it'll hallucinate, but sometimes it actually does a pretty good job at answering the question."}, {"block_idx": 15, "token_num": 14, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And I think like this is just by it happens to be OK."}, {"block_idx": 16, "token_num": 26, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "But what if you could actually like specifically train or post train a model such that it really was built to understand this code base?"}, {"block_idx": 17, "token_num": 13, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "It's an open research question, one that we're quite interested in."}, {"block_idx": 18, "token_num": 46, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And then there's also uncertainty of like, do you want the model to be the thing that end to end is doing everything, IE it's doing the retrieval and it's internals and then kind of answering a question, creating the code?"}, {"block_idx": 19, "token_num": 13, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Or do you want to separate the retrieval from the frontier model?"}, {"block_idx": 20, "token_num": 62, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Or maybe, you know, you'll get some really capable models that are much better than like the best open source ones in a handful of months, and then you want to separately train a really good open source model to be the retriever, to be the thing that feeds in the context to these larger models."}, {"block_idx": 21, "token_num": 18, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Can you speak a little more to the post-training a model to understand the code base?"}, {"block_idx": 22, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Like what do you what do you mean by that?"}, {"block_idx": 23, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "With this is a synthetic data direction."}, {"block_idx": 24, "token_num": 3, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Is this."}, {"block_idx": 25, "token_num": 16, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Yeah, I mean, there are many possible ways you could try doing it."}, {"block_idx": 26, "token_num": 7, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "There's certainly no shortage of ideas."}, {"block_idx": 27, "token_num": 21, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "It's just a question of going in and like trying all them and being empirical about which one works best."}, {"block_idx": 28, "token_num": 22, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "You know, one very naive thing is to try to replicate what's done with VS Code and these frontier models."}, {"block_idx": 29, "token_num": 37, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So let's like continue pre training, some kind of continued pre training that includes general code data, but also throws in a lot of the data of some particular repository that you care about."}, {"block_idx": 30, "token_num": 29, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And then in post training, meaning in let's just start with instruction fine tuning, you have like a normal instruction fine tuning data set about code."}, {"block_idx": 31, "token_num": 14, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Then you throw in a lot of questions about code in that repository."}, {"block_idx": 32, "token_num": 44, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So you could either get ground truth ones which might be difficult, or you could do what you kind of hinted at or suggested using synthetic data, IE kind of having the model ask questions about various pieces of the code."}, {"block_idx": 33, "token_num": 40, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So you kind of take the pieces of the code, then prompt the model, or have a model propose a question for that piece of code and then add those as instruction fine-tuning data points."}, {"block_idx": 34, "token_num": 18, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And then in theory this might unlock the models ability to answer questions about that code base."}, {"block_idx": 35, "token_num": 10, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Let me ask you about OpenAI o1."}, {"block_idx": 36, "token_num": 18, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "What do you think is the role of that kind of test time compute system in programming?"}, {"block_idx": 37, "token_num": 11, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "I think test time compute is really, really interesting."}, {"block_idx": 38, "token_num": 46, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So there's been the pre training regime which will kind of, as you scale up the amount of data and the size of your model, get you better and better performance both on loss and then on downstream benchmarks and just general performance."}, {"block_idx": 39, "token_num": 13, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So we use it for coding or, or or other tasks."}, {"block_idx": 40, "token_num": 24, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "We're starting to hit a bit of a data wall, meaning it's going to be hard to continue scaling up this regime."}, {"block_idx": 41, "token_num": 62, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And so scaling up test time compute is an interesting way of now, you know, increasing the number of inference time flops that we use, but still getting like, like, yeah, as you increase the number of flops used at inference time, getting corresponding improvements in in the performance of these models."}, {"block_idx": 42, "token_num": 23, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Traditionally we just had to literally train a bigger model that always uses that always used that many more flops."}, {"block_idx": 43, "token_num": 31, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "But now we could perhaps use the same size model and run it for longer to be able to get an answer at the quality of a much larger model."}, {"block_idx": 44, "token_num": 47, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And so the really interesting thing I like about this is there are some problems that perhaps require 100 trillion parameter model intelligence trained on 100 trillion tokens, but that's like maybe 1%, maybe like .1% of all queries."}, {"block_idx": 45, "token_num": 33, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So are you going to spend all of this effort, all this compute training model that cost that much and then run it so infrequently it feels completely wasteful?"}, {"block_idx": 46, "token_num": 52, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "When instead you get the model that can, that is that you train the model that is capable doing the 99.9% of queries, Then you have a way of inference time running it longer for those few people that really, really want Max intelligence."}, {"block_idx": 47, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "How do you figure out which problem requires what level of intelligence?"}, {"block_idx": 48, "token_num": 33, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Is that possible to dynamically figure out when to use GPT-4, when to use like, when to use a small model and when you need the o1?"}, {"block_idx": 49, "token_num": 10, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Mean yeah, that's that's an open research problem."}, {"block_idx": 50, "token_num": 15, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Certainly I don't think anyone's actually cracked this model routing problem quite well."}, {"block_idx": 51, "token_num": 89, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "We'd like to we we have like kind of initial implementations of this for things for something like cursor tab, but at the level of like it's going between 4o, Sonnet, to o1, it's a bit trickier, but how like there's also a question like what level of intelligence do you need to determine if the thing is too hard for the for the the four level model, maybe you need the o1 level model."}, {"block_idx": 52, "token_num": 5, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "It it's really unclear."}, {"block_idx": 53, "token_num": 43, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "But, but you mentioned this, so there's a, there's a, there's a pre training process and there's post training and then there's like test-time compute. Does that sort of separate? Where's the biggest gains?"}, {"block_idx": 54, "token_num": 27, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Well, it, it's weird because like test time compute, there's like a whole training strategy needed to get test-time compute to work."}, {"block_idx": 55, "token_num": 35, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And the really, the other really weird thing about this is no one like outside of the big labs and maybe even just open AI, no one really knows how it works."}, {"block_idx": 56, "token_num": 17, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Like there's been some really interesting papers that show hints of what they might be doing."}, {"block_idx": 57, "token_num": 15, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And so it perhaps they're doing something with tree search using process reward models."}, {"block_idx": 58, "token_num": 21, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "But yeah, I just, I think the issue is we don't quite know exactly what it looks like."}, {"block_idx": 59, "token_num": 16, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So it would be hard to kind of comment on like where it fits in."}, {"block_idx": 60, "token_num": 37, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "I would I would put it in post training but maybe like the compute spent for this kind of for getting test time compute to work for a model is going to dwarf pre training eventually."}, {"block_idx": 61, "token_num": 27, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So we don't even know if O1 is using just like chain of thought RL, we don't know how they're using any of these."}, {"block_idx": 62, "token_num": 5, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "I don't know anything."}, {"block_idx": 63, "token_num": 5, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "It's fun to speculate."}, {"block_idx": 64, "token_num": 15, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Like if you were to build a competing model, what would you do?"}, {"block_idx": 65, "token_num": 2, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Yeah."}, {"block_idx": 66, "token_num": 39, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So one thing to do would be I I think you probably need to train a process reward model, which is so maybe we can get into reward models and outcome reward models versus process reward models."}, {"block_idx": 67, "token_num": 24, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Outcome reward models are the kind of traditional reward models that people are trained for these for for language models, language modelling."}, {"block_idx": 68, "token_num": 9, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And it's just looking at the final thing."}, {"block_idx": 69, "token_num": 49, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So if you're doing some math problem, let's look at that final thing you've done everything and let's assign a grade how likely we think like what's the rewards for this, this, this outcome process reward models instead try to grade the chain of thought."}, {"block_idx": 70, "token_num": 40, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "And so OpenAI had some preliminary paper on this, I think last summer where they use human labelers to get this pretty large, several 100,000 data set of grading chains of thought."}, {"block_idx": 71, "token_num": 40, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Ultimately, it feels like I I haven't seen anything interesting in in the ways that people use process reward models outside of just using it as a means of affecting how we choose between a bunch of samples."}, {"block_idx": 72, "token_num": 48, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "So like what people do in all these papers is they sample a bunch of outputs from the language model and then use the process reward models to grade all those generations alongside maybe some other heuristics and then use that to choose the best answer."}, {"block_idx": 73, "token_num": 23, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "The really interesting thing that people think might work and people want to work is tree search with these process reward models."}, {"block_idx": 74, "token_num": 53, "speaker_id": "speaker_4", "speaker_name": "Aman Sanger", "text": "Because if you really can grade every single step of the chain of thought, then you can kind of branch out and, you know, explore multiple paths of this chain of thought and then use these process reward models to evaluate how good is this branch that you're taking."}, {"block_idx": 75, "token_num": 25, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "Yeah, when the when the quality of the branch is somehow strongly correlated with the quality of the outcome at the very end."}, {"block_idx": 76, "token_num": 14, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So like you have a good model of knowing which branch to take."}, {"block_idx": 77, "token_num": 15, "speaker_id": "speaker_1", "speaker_name": "Lex Fridman", "text": "So not just this in the short term in like in the long term."}]}