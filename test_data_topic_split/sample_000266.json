{"sample_idx": 7, "start_block_idx": 715, "last_block_idx": 818, "block_list": [{"block_idx": 0, "token_num": 33, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Like when I want the model to like, say, learn a prompting technique, a lot of the time people will start and they'll start like describing the prompting technique."}, {"block_idx": 1, "token_num": 9, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "I'm just like, give it the paper."}, {"block_idx": 2, "token_num": 22, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "So I do, I give it the paper, and then I'm like, here's a paper about prompting technique."}, {"block_idx": 3, "token_num": 27, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "I just want you to like write down 17 examples of this and then it just does it because I'm like, read the paper."}, {"block_idx": 4, "token_num": 3, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "That's interesting."}, {"block_idx": 5, "token_num": 23, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And I think people don't have that intuition somehow where I'm like, but I'm like, but the paper exists like."}, {"block_idx": 6, "token_num": 11, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "And what when would you want to do this so?"}, {"block_idx": 7, "token_num": 55, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Sometimes if I want, if I want models to like say prompt other models and I or I want to test a new prompting technique, so papers come out on a prompting technique rather than like try to replicate it by like writing up the prompt or just give it the paper."}, {"block_idx": 8, "token_num": 47, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And then I'm like, right, like basically write a meta prompt for this, like write something that would cause other models to like do this or write me a template or like, so all of the stuff that you would normally do."}, {"block_idx": 9, "token_num": 26, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And like if I read a paper and I'm like, oh, I would like the models, I'd like to test that style."}, {"block_idx": 10, "token_num": 8, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "I'm just like, it's right there."}, {"block_idx": 11, "token_num": 34, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Like model can just read the paper, do what I did and then be like, make, make another model do this and then it'll just do the thing you're like."}, {"block_idx": 12, "token_num": 2, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Great."}, {"block_idx": 13, "token_num": 2, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Thanks."}, {"block_idx": 14, "token_num": 21, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I give the advice a lot to customers, just like respect the model and like what it can do."}, {"block_idx": 15, "token_num": 35, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "Like I feel like people feel like they're babying a system a lot of times when they write prompts like it's like, oh, it's this cute little not that smart thing."}, {"block_idx": 16, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I need to like really baby it be like like dumb things down to Claude's level."}, {"block_idx": 17, "token_num": 25, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "And if you just, like, think that Claude is smart and treat it that way, it tends to do pretty good."}, {"block_idx": 18, "token_num": 9, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "But it's like, give it the paper."}, {"block_idx": 19, "token_num": 23, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "It's like, I don't need to write a baby-like dumbed-down version of this paper for Claude to understand."}, {"block_idx": 20, "token_num": 8, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I can just show it the paper."}, {"block_idx": 21, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "Yeah."}, {"block_idx": 22, "token_num": 11, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "And I think that intuition doesn't always map for people."}, {"block_idx": 23, "token_num": 17, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "But that is certainly something that I have come to do more of over time and."}, {"block_idx": 24, "token_num": 16, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "It's interesting because I do think that prompting has and hasn't changed in a sense."}, {"block_idx": 25, "token_num": 35, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Like I think what I will do to prompt the models has probably changed over time, but fundamentally it's a lot of like imagining you put yourself in the place of the model."}, {"block_idx": 26, "token_num": 15, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "So maybe it's like how capable you think the model is changes over time."}, {"block_idx": 27, "token_num": 21, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "I think someone once laughed at me because I was talking about, I was like thinking about a problem."}, {"block_idx": 28, "token_num": 17, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And then they they asked me like what I thought the output of something would be."}, {"block_idx": 29, "token_num": 10, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And they were talking about a pre trained model."}, {"block_idx": 30, "token_num": 21, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And I was like, yeah, I know if I'm a pre trained model, this looks like this."}, {"block_idx": 31, "token_num": 22, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And then they're like, wait, did you just like simulate what it's like to be a pre trained model?"}, {"block_idx": 32, "token_num": 8, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "I'm like, yeah, of course."}, {"block_idx": 33, "token_num": 29, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Like I'm used to just like I try and inhabit the mindspace of a pre trained model and the mindspace of like different RLHF models."}, {"block_idx": 34, "token_num": 25, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And so it's more like the mindspace you try to occupy changes and that can change how you end up prompting the model."}, {"block_idx": 35, "token_num": 50, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "That's why now I just give models papers because as soon as I was like, oh I have the mindspace of this model, it doesn't need me to baby it, it it can just read the ML papers, I'll just give it the literature."}, {"block_idx": 36, "token_num": 19, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "I might even be like, is there more literature you'd like to read to understand this better?"}, {"block_idx": 37, "token_num": 14, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "Do you get any qualia when you're inhabiting the mindspace."}, {"block_idx": 38, "token_num": 17, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "I mean, yes, but just because I'm experiencing qualia all the time anyway."}, {"block_idx": 39, "token_num": 8, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Or as then, do I like?"}, {"block_idx": 40, "token_num": 3, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Is it?"}, {"block_idx": 41, "token_num": 9, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "Different like correlated somehow with which model you're."}, {"block_idx": 42, "token_num": 44, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Yeah, pretrained versus RLHF prompting are very different beasts because when you're when you're trying to simulate what it's like to be a pretrained model, it's almost like I land in the middle of a piece of text or something."}, {"block_idx": 43, "token_num": 10, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "It's just very like unhuman like or something."}, {"block_idx": 44, "token_num": 8, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And then I'm like how what happens?"}, {"block_idx": 45, "token_num": 7, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "What keeps going at this point?"}, {"block_idx": 46, "token_num": 48, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "And so that's like, whereas like with a, an RLHF model, like it's much more like, there's also things where I'm like I might pick up on like subtle things in the, in the query and, and stuff like that."}, {"block_idx": 47, "token_num": 28, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "But yeah, I think I have much more of a like it's easier to inhabit the mindspace of a, of an RLHF model."}, {"block_idx": 48, "token_num": 4, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Yeah, that's."}, {"block_idx": 49, "token_num": 7, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "Because that's more similar to human."}, {"block_idx": 50, "token_num": 21, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Yeah, because like we don't often just like suddenly wake up and are like, I'm just generating text."}, {"block_idx": 51, "token_num": 15, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I just find it easier to hit the mindspace of the pretrained model."}, {"block_idx": 52, "token_num": 40, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I don't know what it is, but like, because RLHF is still like this kind of complex beast that I'm not, it's not like super clear to me that we really understand what's going on."}, {"block_idx": 53, "token_num": 16, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "And so in some ways it's closer to my lived experience, which is easier."}, {"block_idx": 54, "token_num": 23, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "But in some ways I feel like there's all this here there be dragons out there that I don't know about pretrained."}, {"block_idx": 55, "token_num": 14, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I kind of have a decent sense of what the Internet looks like."}, {"block_idx": 56, "token_num": 37, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "If you gave me a piece of text and said what comes next, that would be, I'm not saying I'd do good at it, but I kind of get what's going on there."}, {"block_idx": 57, "token_num": 26, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "And I don't know, after everything that we do after pre training, I don't really claim to get what's going on as much."}, {"block_idx": 58, "token_num": 5, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "Maybe that's just me."}, {"block_idx": 59, "token_num": 28, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "That's something I wonder about is like, is it more helpful to have specifically spent a lot of time reading the Internet versus like reading books?"}, {"block_idx": 60, "token_num": 2, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "Sure."}, {"block_idx": 61, "token_num": 52, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "In order to because I mean, I don't know if books, but like reading stuff that's not on the Internet probably is like less valuable per like word read for predicting what a model will do or building intuition than like reading random garbage from social media or forums."}, {"block_idx": 62, "token_num": 4, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "Yeah, exactly."}, {"block_idx": 63, "token_num": 2, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "Yeah."}, {"block_idx": 64, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "OK, so that's that's the past."}, {"block_idx": 65, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "Now let's move on to the the future of prompt engineering."}, {"block_idx": 66, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "This is the hottest question right now."}, {"block_idx": 67, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "Are we all going to be prompt engineers in the future?"}, {"block_idx": 68, "token_num": 10, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "Is that going to be the final job remaining?"}, {"block_idx": 69, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "Nothing left except us just talking to models all day."}, {"block_idx": 70, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "What does this look like?"}, {"block_idx": 71, "token_num": 23, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "Is prompting going to be necessary or will these models just get like smart enough in the future to not need it?"}, {"block_idx": 72, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "Anybody want to start on that?"}, {"block_idx": 73, "token_num": 3, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "Easy question."}, {"block_idx": 74, "token_num": 53, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I mean, to some extent there's the like the model is getting better at understanding what you want them to do and doing it means that like the amount of thought you need to put into I mean, OK, there's like an information theory way to think of this."}, {"block_idx": 75, "token_num": 17, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "If like you need to provide enough information such that a thing is specified, right?"}, {"block_idx": 76, "token_num": 11, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "Like what you want the model to do is specified."}, {"block_idx": 77, "token_num": 34, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "And to the extent that that's prompt engineering, like I think that will always be around like the ability to actually like clearly state what the goal should be always is fundamental."}, {"block_idx": 78, "token_num": 10, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "If Claude can do that, then that's fine."}, {"block_idx": 79, "token_num": 20, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "Like if Claude is the one setting the goals, then you know, things are out the window."}, {"block_idx": 80, "token_num": 47, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "But in the meanwhile, where we can reason about the world in a more normal way, like I think to some extent it's always going to be important to be able to specify like what are you, what do you expect to happen?"}, {"block_idx": 81, "token_num": 34, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "And that's actually like sufficiently hard that even if the model gets better at intuiting that from between the lines, like I still think there's some amount of writing it well."}, {"block_idx": 82, "token_num": 21, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "But then there's just like, I think the tools and the ways we get there should evolve a lot."}, {"block_idx": 83, "token_num": 12, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "Like Claude should be able to help me a lot more."}, {"block_idx": 84, "token_num": 25, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I should be able to collaborate with Quad a lot more to like figure out what I need to write down and what's missing."}, {"block_idx": 85, "token_num": 12, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I think Claude already does this with me all the time?"}, {"block_idx": 86, "token_num": 12, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "I think Claude already does this with me all the time?"}, {"block_idx": 87, "token_num": 9, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "I think Claude's my prompting assistant now."}, {"block_idx": 88, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "But I think that's not true for most customers that I talked to at the very least."}, {"block_idx": 89, "token_num": 30, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "So in terms of the future, like how you prompt Claude is probably like a decent direction for what the future looks like or how is that like?"}, {"block_idx": 90, "token_num": 25, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "I think maybe this is like a decent place to step back and say like asking them how they prompt Claude now is probably."}, {"block_idx": 91, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Alex Albert", "text": "The future The future for."}, {"block_idx": 92, "token_num": 15, "speaker_id": "speaker_2", "speaker_name": "David Hershey", "text": "The vast majority of people, which is an interesting way to think about."}, {"block_idx": 93, "token_num": 24, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "One freezing cold take is that we'll use models to help us much more in the future, to help us with prompting."}, {"block_idx": 94, "token_num": 28, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "The reason I say it's freezing cold is that I expect we'll use models for everything more, and prompting is something that we have to do."}, {"block_idx": 95, "token_num": 15, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "So we'll probably just use models more to do it along with everything else."}, {"block_idx": 96, "token_num": 13, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "For myself, I've found myself using models to write prompts more."}, {"block_idx": 97, "token_num": 22, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "One thing that I've been doing a lot is generating examples by having them give some realistic inputs to the model."}, {"block_idx": 98, "token_num": 31, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "The model write some answers, I tweak the answers a little bit, which is a lot easier than having to write the full perfect answer myself from scratch."}, {"block_idx": 99, "token_num": 40, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "And then I can churn out lots of these, you know, as far as like people who haven't had as much prompt engineering experience, the the prompt generator can give people like a place to start."}, {"block_idx": 100, "token_num": 50, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "But I think that's just like like a super basic version of what will have in the future, which is high bandwidth interaction between like you and the model as you're writing the prompt where you're giving feedback like, hey, this result wasn't what I wanted."}, {"block_idx": 101, "token_num": 12, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "How can you change it to, to make it better?"}, {"block_idx": 102, "token_num": 18, "speaker_id": "speaker_4", "speaker_name": "Zach Whitten", "text": "And people just grow more comfortable with integrating into everything they do and this thing in particular."}, {"block_idx": 103, "token_num": 13, "speaker_id": "speaker_3", "speaker_name": "Amanda Askell", "text": "Yeah, I'm definitely working a lot with like meta prompts now."}]}