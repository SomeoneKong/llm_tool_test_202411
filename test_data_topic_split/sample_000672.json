{"sample_idx": 14, "start_block_idx": 1270, "last_block_idx": 1355, "block_list": [{"block_idx": 0, "token_num": 16, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "So, you know, like it's it's it's it's a bit subtle here you."}, {"block_idx": 1, "token_num": 30, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Can, by the way, I, I think I it's worth saying that there are things that an LLM like architecture can be expected to do."}, {"block_idx": 2, "token_num": 15, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And those are things which are somewhat aligned with what humans can easily do."}, {"block_idx": 3, "token_num": 32, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And there are things which formal computation can do, but at least the current kind of architecture of things like large language models really is not good at doing and."}, {"block_idx": 4, "token_num": 3, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Like multiplication."}, {"block_idx": 5, "token_num": 71, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Yeah, but yes, as, as an intrinsic feature, but I mean, you know, it's worth realizing that that, you know, probably because the actual architecture of neural Nets is somewhat similar to the actual architecture of brains, the kinds of things and the kinds of decisions that that these types of AIS make a somewhat similar to what humans can do."}, {"block_idx": 6, "token_num": 35, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And so, you know, the, the things it's, it's the things that humans can do, they'll be able to do maybe the things that that only computers can do."}, {"block_idx": 7, "token_num": 11, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Well, only computers will be able to do them."}, {"block_idx": 8, "token_num": 11, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "But I don't think this is important to your argument."}, {"block_idx": 9, "token_num": 29, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And I think you're you're, you're kind of going in, as I understand it, you're going in the direction of saying what defines the wants."}, {"block_idx": 10, "token_num": 34, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "If if you were going to describe the action of the AI in terms of wants, if that's your your form of description, where are those wants going to come from?"}, {"block_idx": 11, "token_num": 9, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Is is that where you're going with this?"}, {"block_idx": 12, "token_num": 18, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "So wanting is an effective way of doing, and that's why humans ended up doing things."}, {"block_idx": 13, "token_num": 18, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Planning is an effective way of getting there, and that's why humans ended up planning things."}, {"block_idx": 14, "token_num": 10, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "We were not explicitly selected to be great planners."}, {"block_idx": 15, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "We were selected to survive and reproduce over and over again."}, {"block_idx": 16, "token_num": 38, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And it turns out that, you know, planning how to bring down a a deer or fight off a vicious ostrich or whatever is more effective than just sending random instructions to your muscles."}, {"block_idx": 17, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "From that perspective, we planning is a bit older than humanity."}, {"block_idx": 18, "token_num": 8, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Right here's the thing that surprised me."}, {"block_idx": 19, "token_num": 35, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "OK, it's a recent thing that I've I've, you know, I got interested in kind of the why biological evolution works, which is somewhat related to why machine learning works."}, {"block_idx": 20, "token_num": 31, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And the question is, if you define an objective and you evolve things, you know, you change the underlying rules of some program to achieve that objective."}, {"block_idx": 21, "token_num": 44, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "The thing that has what's been super surprising to me is you look at the pictures of how the objective is achieved and it's achieved in this incredibly ornate, you would never have invented that way to achieve it kinds of ways."}, {"block_idx": 22, "token_num": 22, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "So in other words, this, you know, given the overall objective, if you ask what's the mechanism?"}, {"block_idx": 23, "token_num": 6, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Can you explain what's happening?"}, {"block_idx": 24, "token_num": 3, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "No way."}, {"block_idx": 25, "token_num": 36, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "It's just that you are, you know, my, my analogy here for, for, you know, for machine learning, for example, is what's actually happening in machine learning."}, {"block_idx": 26, "token_num": 14, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Well, you know, you say I want to build a wall."}, {"block_idx": 27, "token_num": 11, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "OK, you can build a wall out of bricks."}, {"block_idx": 28, "token_num": 27, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "You know, each brick is nicely, you know, shaped and you can sort of engineer the wall by, by arranging the bricks."}, {"block_idx": 29, "token_num": 8, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "But machine learning is not doing that."}, {"block_idx": 30, "token_num": 25, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Machine learning is instead finding kind of lumps of computation, kind of like lying around, like rocks lying around on the ground."}, {"block_idx": 31, "token_num": 29, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And it's managing to find a way to kind of fit those rocks together so that it's successfully builds something which you would consider to be a wall."}, {"block_idx": 32, "token_num": 28, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Or to be exact, like natural selection is fitting rocks together and gradient descent is doing the same thing but the rocks are on a slope."}, {"block_idx": 33, "token_num": 4, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "OK, yes."}, {"block_idx": 34, "token_num": 9, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I mean that that, yeah, right."}, {"block_idx": 35, "token_num": 21, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "But but the basic point is that the raw material are these things which are not built to be understandable."}, {"block_idx": 36, "token_num": 14, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "They just happen to fit in this or that way and I think."}, {"block_idx": 37, "token_num": 32, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And that is where I was going with there that like you apply gradient descent to make the AI models better and better at solving various problems and predicting various things."}, {"block_idx": 38, "token_num": 49, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And along the way, you know, there's these little internal processes that find that they can effectively get where they are going by trying to keep something on a track behaving like a thermostat and being a thermostat is not being like a super intelligent planner."}, {"block_idx": 39, "token_num": 30, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "But this is where the bare beginnings of preference begin to form inside the system is that there's some place inside it where it knows the where where in."}, {"block_idx": 40, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "It's like few layers of like building up of of transformer layers."}, {"block_idx": 41, "token_num": 61, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "I guess I'll just go ahead and say, or in its chain of thought processes, there's it, it, it has been selected to get to some destination and it finds that the way you get to that destination is by, you know, modeling something and seeing like, is it off to the left?"}, {"block_idx": 42, "token_num": 13, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Is it off to the right and steering it back on track."}, {"block_idx": 43, "token_num": 17, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And this is, you know, this is like the, the nematode."}, {"block_idx": 44, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "This is like the tiny earthworm level of wanting things."}, {"block_idx": 45, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "But it is where things begin."}, {"block_idx": 46, "token_num": 24, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And they may be much further than that along the the the trajectory of wanting by now, but we wouldn't necessarily know."}, {"block_idx": 47, "token_num": 58, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Well, the way I would describe it is, you know, if I look inside one of these things that I've evolved, OK, which I can, you know, conveniently, I've, I've gotten nice ways to actually just visualize what's happening, which has been very difficult in neural Nets."}, {"block_idx": 48, "token_num": 26, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I have a simplified version of neural Nets where you can actually visualize what's happening, where you can do training and visualize the results."}, {"block_idx": 49, "token_num": 25, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And the main conclusion is when you visualize the results, the way that the objective is achieved is ornate and incomprehensible."}, {"block_idx": 50, "token_num": 33, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And you know, but nevertheless, you can see, yes, you know, if you look at it, every bit follows every other bit in the right way."}, {"block_idx": 51, "token_num": 15, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And in the end, you can see that it did achieve that objective."}, {"block_idx": 52, "token_num": 40, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And now if what you're saying is that in the achievement of that objective, some particular, you know, training or whatever, some particular Rock You picked up will have a particular shape unknown to you."}, {"block_idx": 53, "token_num": 32, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And which has certain in a sense, preferences that were not put in there that the the only preference was I want to make these rocks assemble into a wall."}, {"block_idx": 54, "token_num": 40, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "The fact that every rock had, you know, a a little pointy bit on one side is not part of what you are defining by just knowing you want to build it up into a wall."}, {"block_idx": 55, "token_num": 30, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "So in a sense, there are there are coincidental preferences that get inserted just by the mechanism of what happens that you didn't put that so to."}, {"block_idx": 56, "token_num": 2, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Speak."}, {"block_idx": 57, "token_num": 4, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "There's multiple levels."}, {"block_idx": 58, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Here is the critical thing."}, {"block_idx": 59, "token_num": 14, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Like when you look at a a fluffy seed dropped by a tree."}, {"block_idx": 60, "token_num": 21, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Evolution has shaped the sea to drift along in the air, but eventually come down and eventually plant itself."}, {"block_idx": 61, "token_num": 10, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "The seed itself is not doing very much thinking."}, {"block_idx": 62, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "A spider is doing some thinking."}, {"block_idx": 63, "token_num": 40, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "A mouse is doing more thinking, humans are doing thinking that is so general that we can start to build our own artifacts that are carefully shaped the same way that evolution builds artifacts that are carefully shaped."}, {"block_idx": 64, "token_num": 39, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "So with with a large language model, you have on the one hand the outer process that is shaping it to be a great predictor and that thing is like very clearly steering in a particular direction."}, {"block_idx": 65, "token_num": 6, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "It's simple, it's code."}, {"block_idx": 66, "token_num": 33, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "We understand the thing that builds the AI model, but the AI model built probably has some fantastically ornate weird stuff going on in there, like human biochemistry."}, {"block_idx": 67, "token_num": 16, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "Only, you know, we can see it and we still can't decrypt it."}, {"block_idx": 68, "token_num": 33, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "And then there's like the plans that it would make if it's doing planning, and it probably does at least some planning if people are correct that they now play chess."}, {"block_idx": 69, "token_num": 42, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "You can't play chess without doing something planning or something like planning or something that of which has the teleology nature of it makes this move because that needs to, because of how that's leads to the final outcome."}, {"block_idx": 70, "token_num": 36, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "So it's like the plans it now makes don't necessarily need to be very ornate, but there's probably a fantastically complex planner in there, if there's a planner in there at all."}, {"block_idx": 71, "token_num": 12, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Well, I, I think, OK, several points."}, {"block_idx": 72, "token_num": 32, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I mean, first of all, this whole question about you, there's some overall thing that's happening and then there are ornate details about how it actually works inside."}, {"block_idx": 73, "token_num": 32, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "I mean, that's true of many physical processes as well as, you know, as well as these processes that you're talking about being sort of intelligence related processes."}, {"block_idx": 74, "token_num": 31, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "So, I mean, you know, as you imagine some flow, flow of water around, you know, rocks that will make some very ornate pattern."}, {"block_idx": 75, "token_num": 30, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And as it carves out pieces of rock, you know, the the overall flow maybe, oh, the river is basically going in this direction."}, {"block_idx": 76, "token_num": 18, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "The water has to go from the top of the hill to the bottom of the hill."}, {"block_idx": 77, "token_num": 31, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "But it carves out this very elaborate pattern on on its way to doing that for reasons of the details of how Water Works and maybe how you know."}, {"block_idx": 78, "token_num": 25, "speaker_id": "speaker_1", "speaker_name": "Eliezer Yudkowsky", "text": "They're they're simple laws governing the water, but the water carves out a very complicated pattern on its way to the bottom."}, {"block_idx": 79, "token_num": 4, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "Yeah, right."}, {"block_idx": 80, "token_num": 39, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "And so, so I mean, I think the that what what's happening in, you know, I agree that as you give sort of all your specifying is sort of play chess or whatever else."}, {"block_idx": 81, "token_num": 25, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "So you were specifying some big kind of objection, what we think of as an objective, the details of what's happening inside."}, {"block_idx": 82, "token_num": 29, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "We will not, you know, there will be aspects of that that we are not in any way able to foresee, predict, whatever else."}, {"block_idx": 83, "token_num": 27, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "So I agree with you that inevitably there are, there are little, you know that the mechanism inside is not one that we understand."}, {"block_idx": 84, "token_num": 7, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "The mechanism inside will not be."}, {"block_idx": 85, "token_num": 22, "speaker_id": "speaker_2", "speaker_name": "Stephen Wolfram", "text": "If we took apart that mechanism and we say is this mechanism doing what we expect here, it won't be."}]}