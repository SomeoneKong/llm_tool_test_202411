{"sample_idx": 12, "start_block_idx": 446, "last_block_idx": 496, "block_list": [{"block_idx": 0, "token_num": 60, "speaker_id": "speaker_6", "speaker_name": "Cage", "text": "因为其实一方面我们看到open AI的AMA hour，他他会说，哎，我们只是one model one model，但是与此同时呢，norm Brown，正好前面苏慧提到了这个年轻学者，他最近在招聘的一个岗位就是multi agent，呃，那个做。"}, {"block_idx": 1, "token_num": 2, "speaker_id": "speaker_6", "speaker_name": "Cage", "text": "Research."}, {"block_idx": 2, "token_num": 103, "speaker_id": "speaker_6", "speaker_name": "Cage", "text": "提的Alpha go Alpha zero那套系统，其实它一个network也不是，呃，也也不是单目标的。它同时有policy network有value network，那么它同时在做执行任务和评估两件事儿。那么不知道，呃，几位嘉宾，呃，看来，呃，O one如果要去复现的话，有没有它可能它是一个多模型组组起来的系统，还是它可能就是一个神经网络解决了所有的问题。"}, {"block_idx": 3, "token_num": 11, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "纯猜测，不用为猜测结果负责。"}, {"block_idx": 4, "token_num": 58, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "我那天看到知乎上面有一篇也是猜测文章，他说我这纯猜测要按照这个训练，把公司把不把公司训倒闭了，我不负责。所以大家只是只想听听大家会思考这个问题的这个思路而已。"}, {"block_idx": 5, "token_num": 48, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "其实我比较同意，就是之前Eric说的就是我刚才讲的五个不同level的这个这个呃aji pass那这个呃第一个conversation呢？第一个是叫conversation no，还是叫什么来着？"}, {"block_idx": 6, "token_num": 59, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "啊，已经做完了对吧？那现在它属于第二个level，which is啊reasoner啊。我个人觉得如果根据它的roden map而言的话，我更倾向于my personal opinion是一个，它是一个单一的大模型，不过the next one那个历史。"}, {"block_idx": 7, "token_num": 18, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "What do you open and highly possible share a multi agent at the most or at least."}, {"block_idx": 8, "token_num": 6, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "单一age的模型。"}, {"block_idx": 9, "token_num": 31, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "你觉得这个是更从这个呃这个这个效果或者说open的这么一个技术审美路径的角度去去猜测的。"}, {"block_idx": 10, "token_num": 60, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "啊，对，我觉得更多是从它的一些strategic的方式来做吧。我觉得我觉得更多时候是我觉得one thing a time吧，就是，嗯，你可以首先做个非常好的chatbot，就是个很好的base模型，你有了base好的chatbot的模型之后。"}, {"block_idx": 11, "token_num": 119, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "啊，你可以用它prom出来很多reason的数据，OK，你可以做很强的reasoning的模型啊。但是reasoning之后，你可以用更强的reasoning来做更好的这个tool use啊。那有可能和function call你有可能可以做到下一版的模型。我觉得我，我更倾向于就是，呃呃，open的research的direction，就是说它不是一种over engineer solution啊。我觉得sofa大家还没有找到一个怎么去train multi agent的，最好的一个就是在multi agent在LM应用做多agent的。"}, {"block_idx": 12, "token_num": 90, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "这个呃啊，我重新说一遍，大家还没有找到一个非常好的去train multi agent的LM的一个一个方式吧。我觉得我更像倾向于说它可以先，比如soft low hanging through let just get a strong reasoning模型，它基于这个base模型，它可以做到下一步的东西，eventually，它可以for它的road map来达到它想，呃，它心目中的这个level five。"}, {"block_idx": 13, "token_num": 4, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "Well, Google."}, {"block_idx": 14, "token_num": 8, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "我搜了一下，OK，然后。"}, {"block_idx": 15, "token_num": 23, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "AI Level 2 Reasoners, Level 3 Agents, Level 4 Innovators, Level 5 organizations."}, {"block_idx": 16, "token_num": 16, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "所以大家觉得我们现在就是在还在reasoner跟agents的阶段。"}, {"block_idx": 17, "token_num": 19, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "对，我觉得有可能属于这个2.1到2.5的这个状态吧。"}, {"block_idx": 18, "token_num": 119, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "其实multi agent，原来我们在应用层面说的会比较多一些，应用层面用multi agent这种架构来去做的时候也会遇到一些这个反对声音，是说啊，我之所以用到multi agent which就是增加了这个呃，整个这个系统的复杂性，然后你中间的很多通信其实有可能又造成很多浪费，本质原因其实就是你的这个呃agent自己本身不够牛逼，如果你有一个很牛逼的一个agent的话，在很多场景下，其实你并不需要。"}, {"block_idx": 19, "token_num": 12, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "So in that Tanu Robotics have the self driving car."}, {"block_idx": 20, "token_num": 32, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "的这个model来去来去取代原来这个model的这个呃system我好奇的这个这个这个路径选择上的一些trade off。"}, {"block_idx": 21, "token_num": 73, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "我觉得大概有这么几个问题需要，呃，回答一下，就是我觉得首先就是我们可以go through一下这个multi-agent这件事情的history吧，我觉得这个multi-agent其实也是就是classical RL的一个topic，我觉得最famous的一篇paper应该也是就是David Silver的，我非常爱的一篇论文，MADDPG。"}, {"block_idx": 22, "token_num": 10, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "MADDPG, Multi-Agent Deep Deterministic"}, {"block_idx": 23, "token_num": 11, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "Multi-Agent Deep Deterministic Policy Gradient, Yeah."}, {"block_idx": 24, "token_num": 113, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "所以说我们之前说就是说你可以做DDPG是Deterministic Policy Gradient，就相当于说你只是在一个environment里面train一个agent做一件事，MADDPG是说你可以train很多agent来做一个不是zero-sum game的一个collaboration task，那它会中间有一些很多的这个complexity，就是它做了很多的简化。Otherwise呢，就是我记得就是如果你不做这些简化，它有可能就是个非常非常computation-wise infeasible的一个问题，我觉得这是。"}, {"block_idx": 25, "token_num": 78, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "Multi-agent，我知道的一些这个background，有有可能在此之后也有很多multi-agent的research，然后我其实在MADDPG之后没有再去follow这件事情，然后说完这个multi-agent，就是说我们再说这个multi-agent的language model的这个应用，其实就是说你可以prompt一个模型，让它做一件事情对吧？你可以prompt这个。"}, {"block_idx": 26, "token_num": 26, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "OK, you know in Step 1, you know, putting your generative model hat on generating this right now you can."}, {"block_idx": 27, "token_num": 32, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "所以就是说你把第一步做完之后，你chain of thought第二步，你跟他说okay now put your critic hat on，you know，helping。"}, {"block_idx": 28, "token_num": 5, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "Keep your own results."}, {"block_idx": 29, "token_num": 24, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "Now this version of you, OK, give me a summary, but this version of you, OK Think very carefully."}, {"block_idx": 30, "token_num": 15, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "If you think everything's right, right, give me a final result."}, {"block_idx": 31, "token_num": 9, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "Otherwise, go back to step number one."}, {"block_idx": 32, "token_num": 4, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "Do it again."}, {"block_idx": 33, "token_num": 112, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "其实你可以理解成它其实中间这一个模型干了很多的事情，对吧？你可以理解成这其实more or less，你不能叫它multi-agent的，它其实还是multi-task，对吧？但是这个multi-task的时候，这个模型有可能它没有办法，非常容易把它的attention，就是它现在做generation，再到critic给它转回来，大家现在做的multi-agent都是个什么东西呢？在language model，只是说你prompt不同模型的这个persona啊，你就说这个模型就是说assume有。"}, {"block_idx": 34, "token_num": 14, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "Generator, your task is just generating things and then generally you separate."}, {"block_idx": 35, "token_num": 73, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "Which is just criticizes the results我觉得这是就是说这个这个language model，就是说如果你想做multi-agent的一个一个一个应用啊，就是我其实so far没有没有有可能我我没有follow the most frontier of the multi-agent research on language model but I think that's very interesting direction especially就是大家想做的下一个level是agent的话。"}, {"block_idx": 36, "token_num": 85, "speaker_id": "speaker_4", "speaker_name": "Kimi Kong", "text": "我其实更倾向于，其实短期我们更多是可以看到一些single agent的这个breakthrough，就跟传统意义上的RO1样，因为RO首先的breakthrough都是在single agent的breakthrough出现的，然后在single agent的breakthrough的时候，你有一个非常强的agent，其实有可能你会非常容易泛化出用同样类似的训练方法来训练出multi-agent的。"}, {"block_idx": 37, "token_num": 5, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "这样一个的R。"}, {"block_idx": 38, "token_num": 4, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "O听听。"}, {"block_idx": 39, "token_num": 7, "speaker_id": "speaker_1", "speaker_name": "Monica", "text": "End to end or multi agent."}, {"block_idx": 40, "token_num": 60, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "我我我的猜想比较保守，我觉得他可能是一个single或者two agents这种的一个情况，但是应该不会不太可能会是更多的一个multi-agent的一个system。嗯，是因为我是这样思考的，因为，呃，刚才Kimi也聊了。"}, {"block_idx": 41, "token_num": 6, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "Let's verify step by step."}, {"block_idx": 42, "token_num": 4, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "They can paper."}, {"block_idx": 43, "token_num": 72, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "以及之前呃，OpenAI也做了很多，呃，关于reasoning and verification这种两个agent在解一些呃，数学或者coding题目的这种framework setup，所以我觉得可能保守的估计，我觉得o1可能它大概率可能只是一个single agent，但是有可能它可能在inference时候或许会。"}, {"block_idx": 44, "token_num": 9, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "Yeah, incorporate its critic or light supervision."}, {"block_idx": 45, "token_num": 2, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "Verify."}, {"block_idx": 46, "token_num": 71, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "或者加一些reward在里面，所以这是我作为o1现在的猜想，然后，呃，莫妮卡，刚才你的有一个问题问的很有意思，就是说在未来，那如果一个为什么你问到就是为什么，就是大家一个challenge对multi-agent呢是说呃，是说因为single agent不够强大。"}, {"block_idx": 47, "token_num": 2, "speaker_id": "speaker_6", "speaker_name": "Cage", "text": "嗯。"}, {"block_idx": 48, "token_num": 22, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "我觉得这个是要看这个single agent的能力的，呃，现在的情况我觉得是。"}, {"block_idx": 49, "token_num": 96, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "以及未来很多很多很久的情况，我觉得都是multi-agent应该会还是会outperform single agent的能力，因为，嗯，可以考虑，呃，即使我们现在人类也是需要就是，呃，多多多个人相互合作分工，然后做出来的事情一般会比一个人会做的更好一点啊。因为不只是普通人类，包括是像爱因斯坦那种level，爱因斯坦也会make mistake。"}, {"block_idx": 50, "token_num": 81, "speaker_id": "speaker_3", "speaker_name": "Eric Li", "text": "啊，在，呃，就是我，我因为是读物理的PhD，所以我知道上个世纪做quantum physics可能有一堆人，然后真的真的是合作分工，然后才能真正呃build up这样一个呃物理的理论，所以我觉得即使你的我们的嗯或者说至少我们的single agent的到达爱因斯坦那个智商水平之前。"}]}